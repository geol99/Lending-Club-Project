---
title: "LendingClubLoanDefaultClassification"
author: "Vikas Pulpa"
date: "`r Sys.Date()`"
output: html_document
---

```{r Load Packages, include=FALSE}

if(!require(tidyverse))
{
  install.packages('tidyverse');
}

if(!require(car))
{
  install.packages('car');
}

if(!require(nortest))
{
  install.packages('nortest');
}

if(!require(MASS))
{
  install.packages('MASS');
}

if(!require(ggplot2))
{
  install.packages('ggplot2');
}

if(!require(caret))
{
  install.packages('caret');
}

if(!require(caret))
{
  install.packages('caret');
}

if(!require(corrplot))
{
  install.packages('corrplot');
}

if(!require(e1071))
{
  install.packages('e1071');
}

if(!require(readr))
{
  install.packages('readr');
}

if(!require(reshape2))
{
  install.packages('reshape2');
}

if(!require(skimr))
{
  install.packages('skimr');
}

if(!require(stringr))
{
  install.packages('stringr');
}

if(!require(rstatix))
{
  install.packages('rstatix');
}

if(!require(xgboost))
{
  install.packages('xgboost');
}

if(!require(randomForest))
{
  install.packages('randomForest');
}

if(!require(ranger))
{
  install.packages('ranger');
}

if(!require(pROC))
{
  install.packages('pROC');
}

if(!require(vip))
{
  install.packages('vip');
}

if(!require(varImp))
{
  install.packages('varImp');
}

if(!require(glmnet))
{
  install.packages('glmnet');
}


require(tidyverse)
require(car)
require(nortest)
require(MASS)
require(ggplot2)
require(caret)
require(corrplot)
require(e1071)
require(readr)
require(dplyr)
require(reshape2)
require(skimr)
require(stringr)
require(rstatix)
require(smotefamily)
require(xgboost)
require(rpart.plot)
require(randomForest)
require(ranger)
require(Matrix)
require(pROC)
require(vip)
require(varImp)
require(glmnet)

rm(list= ls())
```


#### **1. Read the csv into a tibble data structure**


```{r read csv into Tibble}
lendingClubData  <- read_csv('E:\\OneDrive - Microsoft\\StatisticsMasters\\STAT656\\Homework\\Project\\Task3\\Data\\LoanStats3a.csv')
```

#### **2. Looking at the data parsing issues and cleaning up the excel file**

```{r look at the parsing issues}
problems(lendingClubData)
```

On examining the excel sheet, we observed that the lines 39788 and 39789 were blank except that it indicates the subsequent rows indicate that loan where granted out of policy.

Therefore, we edited the excel to:

* Deleted those two rows 39788 and 39789 from excel.
* Added a new feature IsLoanMeetsPolicy that takes value of 'Yes' for the loans that meet the policy (first 39786 rows) and 'No' for the ones that don't.

#### **3. Read the new csv into a tibble data structure**

```{r Reading the new csv into Tibble}

lendingClubData  <- read_csv(
                              'E:\\OneDrive - Microsoft\\StatisticsMasters\\STAT656\\Homework\\Project\\Task3\\Data\\LoanStats3aCleaned.csv'
                             ,show_col_types = FALSE
                            )

lendingClubData  <- read.csv(
                               'E:\\OneDrive - Microsoft\\StatisticsMasters\\STAT656\\Homework\\Project\\Task3\\Data\\LoanStats3aCleaned.csv'
                             , stringsAsFactors = FALSE
                             , na.strings=c("","NA")
                            )
lendingClubData <-  as_tibble(lendingClubData) #convert it to tibble
```

#### **4. Explore the Data **

```{r Explore Lending Club Data}
dim(lendingClubData)
#lendingClubData
```

#### **5. Data Pre-Processing **


##### **5. a. Look at the data structures **

```{r Checking data types 2}
table(sapply(lendingClubData[1,],class))
```

##### **5. b. Look at the missing values and perform Featurewise imputation **

```{r function ggplot_missing}

ggplot_missing <- function(x){

	#### This function produces a plot of the missing data pattern in x.  It is a modified version of a function in the 'neato' package
  
  my_colors <- RColorBrewer::brewer.pal(12, "Paired")[6:7]
  
  x %>% 
    is.na %>%
    melt %>%
    ggplot(data = ., aes(x = Var2, y = Var1)) +
      geom_raster(aes(fill = value)) +
      #scale_fill_brewer(name = "", labels = c("Present","Missing"), palette="Paired", direction = -1) +
      scale_fill_manual(name = "", labels = c("Present","Missing"), values = c(my_colors[2], my_colors[1])) +
      theme_minimal() + 
      theme(axis.text.x  = element_text(angle=45, vjust=0.5)) + 
      labs(x = "Variables in Dataset", y = "Rows / observations")
}

```

```{r getMode Function}

getMode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

```


```{r Missing Data Plot}
ggplot_missing(lendingClubData %>% dplyr::select(-loan_status))
```

```{r find the columns which has more than 50% missing values}

featureCount <- rep(0, 5)
for(i in 1:5) {
  featureCount[i] <-  sum(ifelse(sapply(lendingClubData, function(x){ sum(is.na(x))*100./nrow(lendingClubData) }) <= i * 10.0 , 1, 0))
}
```

```{r % of missing values}
PercentageOfNullValues <- c('10 % or less', '20 % or less', '30 % or less', '40 % or less', '50 % or less')
(missingValueColumns <- data.frame (PercentageOfNullValues, featureCount))

columnVector <- ifelse(sapply(lendingClubData, function(x){ sum(is.na(x))*100./nrow(lendingClubData) }) <= 50.0 , 1, 0)
```


```{r remove the columns that has more than 50% of the data missing}
lendingClubDataReduced <- lendingClubData %>% select_if(columnVector == 1)
dim(lendingClubDataReduced)
ggplot_missing(lendingClubDataReduced)
```

##### **5. c. Remove the unnecessary columns based on the row count **

```{r Checking data types 3}

numericColumns   <- names(lendingClubDataReduced) [sapply(lendingClubDataReduced[1, ], class) == "numeric"]
integerColumns   <- names(lendingClubDataReduced) [sapply(lendingClubDataReduced[1, ], class) == "integer"]
characterColumns <- names(lendingClubDataReduced) [sapply(lendingClubDataReduced[1, ], class) == "character"]
logicalColumns   <- names(lendingClubDataReduced) [sapply(lendingClubDataReduced[1, ], class) == "logical"]

```


```{r remove unnecessary CHARACTER columns}
sapply(lendingClubDataReduced[, characterColumns], function(x) {length(unique(x))})

lendingClubDataReduced <- lendingClubDataReduced %>%
                           dplyr::select( - c(
                                                 emp_title, verification_status, pymnt_plan, url, desc, title, zip_code
                                               , last_pymnt_d, application_type, initial_list_status
                                              )
                                        )
```


```{r remove unnecessary Integer columns}

sapply(lendingClubDataReduced[, integerColumns], function(x) {length(unique(x))})

lendingClubDataReduced <- lendingClubDataReduced %>%
                           dplyr::select( - c(member_id, policy_code, -collections_12_mths_ex_med) )

```


##### **5. d. Remove the unnecessary columns after looking at the data dictionary **

The following features are not required since we are classifying the risk of default before the loan is funded.
*Note, we will keep installment to see if the user defaults for the given installment.

* funded_amnt
* funded_amnt_inv
* int_rate
* issue_d
* out_prncp
* out_prncp_inv
* total_pymnt
* total_pymnt_inv
* total_rec_prncp
* total_rec_int
* total_rec_late_fee
* recoveries
* collection_recovery_fee
* last_pymnt_amnt
* last_credit_pull_d
* last_pymnt_d
* next_pymnt_d


```{r Deleting information not known at the time of loan origination.}

featureList              <- c(
                                'funded_amnt',             'funded_amnt_inv', 'int_rate',           'issue_d',       'out_prncp',          'out_prncp_inv'
                               ,'total_pymnt',             'total_pymnt_inv', 'total_rec_prncp',    'total_rec_int', 'total_rec_late_fee', 'recoveries'
                               ,'collection_recovery_fee', 'last_pymnt_amnt'
                             )

lendingClubDataReduced   <- lendingClubDataReduced %>% dplyr::select(-all_of(featureList))

```


```{r Remove Numeric Columns whose sum is 0}

lendingClubDataReducedNumeric <- lendingClubDataReduced[,sapply(lendingClubDataReduced, class) != 'character']
zeroSumColumns <- colnames(lendingClubDataReducedNumeric[,colSums(lendingClubDataReducedNumeric,na.rm = TRUE)==0])
zeroSumColumns

lendingClubDataReduced <- lendingClubDataReduced %>%
                            dplyr::select(-all_of(zeroSumColumns))
```


```{r Checking data types}

numericColumns   <- names(lendingClubDataReduced) [sapply(lendingClubDataReduced[1, ], class) == "numeric"]
integerColumns   <- names(lendingClubDataReduced) [sapply(lendingClubDataReduced[1, ], class) == "integer"]
characterColumns <- names(lendingClubDataReduced) [sapply(lendingClubDataReduced[1, ], class) == "character"]

```


##### **5. e. Variable Cleanup **

The following columns have wrong date format. Therefore changing them to the correct format:
* earliest_cr_line
* last_credit_pull_d


```{r Change Format for earliest_cr_line}
## Format(1): Month-Year: Jan-00
lendingClubDataReduced_1                           <- lendingClubDataReduced %>%
                                                        filter(str_detect(earliest_cr_line, c("^J|^F|^M|^A|^S|^O|^N|^D")))

## Format(2): Year-Month: 1-Jan
lendingClubDataReduced_2  <- lendingClubDataReduced %>%
                              filter(str_detect(earliest_cr_line, c("^1|^2|^3|^4|^5|^6|^7|^8|^9|^10|^11|^12|^13|^14|^15|^16|^17|^18|^19|^20")))

# Convert the format of earliest_cr_line to Date
lendingClubDataReduced_1$earliest_cr_line         <- as.Date(sub("$","-01",lendingClubDataReduced_1$earliest_cr_line), "%b-%y-%d") 
lendingClubDataReduced_2$earliest_cr_line         <- as.Date(sub("^","01-",lendingClubDataReduced_2$earliest_cr_line), "%d-%y-%b")
        
lendingClubDataReduced_ecl_Changed                <- bind_rows(lendingClubDataReduced_1,lendingClubDataReduced_2)

lendingClubDataReduced_Remaining                  <- anti_join(lendingClubDataReduced, lendingClubDataReduced_ecl_Changed, by = 'id')
lendingClubDataReduced_Remaining$earliest_cr_line <- as.Date(lendingClubDataReduced_Remaining$earliest_cr_line)

lendingClubDataReduced                            <- bind_rows(lendingClubDataReduced_1,lendingClubDataReduced_2,lendingClubDataReduced_Remaining)

```


```{r Change Format for last_credit_pull_d}

## Format(1): Month-Year: Jan-00
lendingClubDataReduced_1                           <- lendingClubDataReduced %>%
                                                        filter(str_detect(last_credit_pull_d, c("^J|^F|^M|^A|^S|^O|^N|^D")))

## Format(2): Year-Month: 1-Jan
lendingClubDataReduced_2  <- lendingClubDataReduced %>%
                              filter(str_detect(last_credit_pull_d, c("^1|^2|^3|^4|^5|^6|^7|^8|^9|^10|^11|^12|^13|^14|^15|^16|^17|^18|^19|^20")))

# Convert the format of earliest_cr_line to Date
lendingClubDataReduced_1$last_credit_pull_d         <- as.Date(sub("$","-01",lendingClubDataReduced_1$last_credit_pull_d), "%b-%y-%d") 
lendingClubDataReduced_2$last_credit_pull_d         <- as.Date(sub("^","01-",lendingClubDataReduced_2$last_credit_pull_d), "%d-%y-%b")
        
lendingClubDataReduced_lcp_Changed                  <- bind_rows(lendingClubDataReduced_1,lendingClubDataReduced_2)

lendingClubDataReduced_Remaining                    <- anti_join(lendingClubDataReduced, lendingClubDataReduced_lcp_Changed, by = 'id')
lendingClubDataReduced_Remaining$last_credit_pull_d <- as.Date(lendingClubDataReduced_Remaining$last_credit_pull_d)

lendingClubDataReduced                              <- bind_rows(lendingClubDataReduced_1,lendingClubDataReduced_2,lendingClubDataReduced_Remaining)

```


```{r Removing id feature}
lendingClubDataReduced <- lendingClubDataReduced %>%
                            select(-id)

```


##### **5. f. Datatype Formatting & Conversion **


1. Format:
*  term
*  loan_status
*  revol_util
*  emp_length

```{r Character Variable Formatting & Conversion}

lendingClubDataCleaned  <- lendingClubDataReduced %>% 
                              mutate(term = str_replace(term, "months", "")) %>% 
                              mutate_at("term", as.numeric) %>% 
                              mutate(loan_status = str_replace(loan_status, "Does not meet the credit policy. Status:", "")) %>% 
                              mutate(emp_length = str_replace_all(
                                                                  emp_length, 
                                                                  c('< 1 year' = '0 years' , '10\\+ years' = '10 years', "n/a" = NA, "years" = "", "year" = "")                                                                   )
                                     ) %>%
                              mutate_at("emp_length", as.numeric) %>%
                              mutate(revol_util = str_replace(revol_util, "%", "")) %>% 
                              mutate_at("revol_util", as.numeric)

```


```{r Checking data types again}

numericColumns   <- names(lendingClubDataCleaned) [sapply(lendingClubDataCleaned[1, ], class) == "numeric"]
integerColumns   <- names(lendingClubDataReduced) [sapply(lendingClubDataReduced[1, ], class) == "integer"]
characterColumns <- names(lendingClubDataCleaned) [sapply(lendingClubDataCleaned[1, ], class) == "character"]

```


##### **5. g. Numeric Features Imputation **


```{r % of Missing Values}
missingValueColumns <- data.frame(sapply(lendingClubDataCleaned, function(x){ sum(is.na(x))*100./nrow(lendingClubData) }))
missingValueColumns <- cbind(variable = row.names(missingValueColumns), missingValueColumns)

names(missingValueColumns) <- c("MissingValueColumn", "MissingValuePercent")
missingValueColumns %>% 
  dplyr::filter(MissingValuePercent != 0) %>% 
  arrange(desc(MissingValuePercent))
```


For the following columns NA might indicate that the data entry operator might have inputted nothing or there is not value to be entered for the applicant.

* pub_rec_bankruptcies has only 3 values {0, 1, 2} with most of the values 0.
* tax_liens has only 2 values {0, 1} with most of the values 0.
* delinq_2yrs.
* inq_last_6mths
* pub_rec
* acc_now_delinq has only 2 values {0, 1} with most of the values 0.
* delinq_amnt

Therefore replacing NA with 0


```{r Data Imputation: Replacing NA with 0}

lendingClubDataImputed <- lendingClubDataCleaned %>% 
                            mutate(pub_rec_bankruptcies = if_else(is.na(pub_rec_bankruptcies), 0L, pub_rec_bankruptcies)) %>%
                            mutate(tax_liens = if_else(is.na(tax_liens), 0L, tax_liens)) %>%
                            mutate(delinq_2yrs = if_else(is.na(delinq_2yrs), 0L, delinq_2yrs)) %>%
                            mutate(inq_last_6mths = if_else(is.na(inq_last_6mths), 0L, inq_last_6mths)) %>%
                            mutate(pub_rec = if_else(is.na(pub_rec), 0L, pub_rec)) %>%
                            mutate(acc_now_delinq = if_else(is.na(acc_now_delinq), 0L, acc_now_delinq)) %>%
                            mutate(delinq_amnt = if_else(is.na(delinq_amnt), 0L, acc_now_delinq))

```

Performing the mean/median/mode/quantile imputation for the following columns:

* emp_length
* revol_util
* open_acc
* total_acc
* annual_inc

```{r Data Imputation: emp_length - First Quantile Imputation) }

summary(lendingClubDataImputed$emp_length)
quantile(lendingClubDataImputed$emp_length, na.rm = TRUE)

boxplot(lendingClubDataImputed$emp_length)
plot(density(lendingClubDataImputed$emp_length[!is.na(lendingClubDataImputed$emp_length)], bw = "nrd"))


lendingClubDataImputed <- lendingClubDataImputed %>%
                            mutate(emp_length = if_else(is.na(emp_length), quantile(emp_length, na.rm = TRUE)[2] , emp_length))

points(density(lendingClubDataImputed$emp_length[!is.na(lendingClubDataImputed$emp_length)], bw = "nrd"), type = "l", col = "maroon")

```

```{r Data Imputation: revol_util - Mean Imputation) }

summary(lendingClubDataImputed$revol_util)
quantile(lendingClubDataImputed$revol_util, na.rm = TRUE)

boxplot(lendingClubDataImputed$revol_util)
plot(density(lendingClubDataImputed$revol_util[!is.na(lendingClubDataImputed$revol_util)], bw = "nrd"))


lendingClubDataImputed <- lendingClubDataImputed %>%
                           mutate(revol_util = if_else(is.na(revol_util), mean(revol_util, na.rm = TRUE) , revol_util))

points(density(lendingClubDataImputed$revol_util[!is.na(lendingClubDataImputed$revol_util)], bw = "nrd"), type = "l", col = "maroon")

```

```{r Data Imputation: open_acc - Median Imputation) }

summary(lendingClubDataImputed$open_acc)
quantile(lendingClubDataImputed$open_acc, na.rm = TRUE)

boxplot(lendingClubDataImputed$open_acc)
plot(density(lendingClubDataImputed$open_acc[!is.na(lendingClubDataImputed$open_acc)], bw = "nrd"))


lendingClubDataImputed <- lendingClubDataImputed %>%
                           mutate(open_acc = if_else(is.na(open_acc), as.integer(median(open_acc, na.rm = TRUE)), open_acc))

points(density(lendingClubDataImputed$open_acc[!is.na(lendingClubDataImputed$open_acc)], bw = "nrd"), type = "l", col = "maroon")

```
```{r Data Imputation: total_acc - median Imputation) }

summary(lendingClubDataImputed$total_acc)
quantile(lendingClubDataImputed$total_acc, na.rm = TRUE)

boxplot(lendingClubDataImputed$total_acc)
plot(density(lendingClubDataImputed$total_acc[!is.na(lendingClubDataImputed$total_acc)], bw = "nrd"))


lendingClubDataImputed <- lendingClubDataImputed %>%
                           mutate(total_acc = if_else(is.na(total_acc), as.integer(median(total_acc, na.rm = TRUE)), total_acc))

points(density(lendingClubDataImputed$total_acc[!is.na(lendingClubDataImputed$total_acc)], bw = "nrd"), type = "l", col = "maroon")

```

```{r Data Imputation: annual_inc - Median Imputation) }

summary(lendingClubDataImputed$annual_inc)
quantile(lendingClubDataImputed$annual_inc, na.rm = TRUE)

boxplot(lendingClubDataImputed$annual_inc)
plot(density(lendingClubDataImputed$annual_inc[!is.na(lendingClubDataImputed$annual_inc)], bw = "nrd"))


lendingClubDataImputed <- lendingClubDataImputed %>%
                           mutate(annual_inc = if_else(is.na(annual_inc), median(annual_inc, na.rm = TRUE) , annual_inc))

points(density(lendingClubDataImputed$annual_inc[!is.na(lendingClubDataImputed$annual_inc)], bw = "nrd"), type = "l", col = "maroon")

```

```{r Mode Imputing the Date Colulmns}
lendingClubDataImputed <- lendingClubDataImputed %>% 
                            mutate(earliest_cr_line   = if_else(is.na(earliest_cr_line), getMode(earliest_cr_line), earliest_cr_line))  %>% 
                            mutate(last_credit_pull_d = if_else(is.na(last_credit_pull_d), getMode(last_credit_pull_d), last_credit_pull_d))
```

```{r adding new columns}

lendingClubDataImputed <- lendingClubDataImputed %>% 
                            mutate(lastCreditPulledYear = format(last_credit_pull_d, "%Y"))%>% 
                            mutate(earliestCreditLineYear = format(earliest_cr_line, "%Y"))
```

```{r Looking at missing values once again}
dim(lendingClubDataImputed)
ggplot_missing(lendingClubDataImputed)
```


##### **6. Univariate Analysis **

##### **6. a. Looking at feature that have low SD **

```{r Summary Statistics}
skim(lendingClubDataImputed)
```

##### **6. b. Looking at relationship between feature and supervisor and also the features that have low SD **

Filtering the data so that we have only "Charged Off" and "Fully Paid" loan statuses.
The rest of the loan statuses does not help in classification.

```{r lendingClubDataImputed}
lendingClubDataFiltered <- lendingClubDataImputed %>% dplyr::filter(loan_status %in% c("Charged Off", "Fully Paid"))
```

From the data analysis, we can remove the following columns:
* acc_now_delinq
* delinq_amnt
* tax_liens

```{r removing feature further}
lendingClubDataFiltered <- lendingClubDataFiltered %>% dplyr::select(-c(acc_now_delinq, delinq_amnt, tax_liens))
```


##### **7.Variability Check **

```{r Variability Check preProcess Method}

nearZeroVarRes <- nearZeroVar(lendingClubDataFiltered, saveMetrics = TRUE)
nearZeroVarRes[nearZeroVarRes$zeroVar == TRUE | nearZeroVarRes$nzv == TRUE, ]

```
##### **8. Correlation Filtering **

```{r Correlation Plot}
quantitativeColumns   <- names(lendingClubDataFiltered) [
                                                            sapply(lendingClubDataFiltered[1, ], class) == "numeric" | 
                                                            sapply(lendingClubDataFiltered[1, ], class) == "integer"
                                                        ]

corrleation           <- cor(lendingClubDataFiltered[, quantitativeColumns], use="pairwise.complete.obs", method="pearson")
corrplot(corrleation, method='number', type = 'upper', tl.cex=.5, number.cex=0.5)
``` 

```{r Correlation Filtering}
highlyCorrelatedFeature           <- findCorrelation(corrleation, 0.80, names = TRUE)
highlyCorrelatedFeature

lendingClubDataFilteredWithoutCor  <- lendingClubDataFiltered %>%
                                        dplyr::select(-pub_rec_bankruptcies, -installment, -total_acc)
dim(lendingClubDataFilteredWithoutCor)
```

### Based on the Bivariate analysis above:

* Charged Off Loans are associated with higher mean Loan Amount.
* 60-month-term loans are twice likely to be Charged Off compared to 36-month-term loan.
* Charged Off Loans are associated with higher mean Installment Amount.
* There is higher probability of charge off as the sub_grade goes from A to G
* Renters and homeowners have a higher probability of charge-off.
* Charged Off Loans are associated with lower mean Annual Income.
* Small Businesses(Purpose) seem to have a higher charge off probability for loans.
* Charged Off Loans are associated with higher mean dti.
* Charged Off Loans are associated with higher number of deliquent account in past two years.
* Charged Off Loans are associated with higher number of inquires in past 6 months.
* Charged Off Loans are associated with higher number of inquires in past 6 months.
* Charged Off Loans are associated with higher number of public records.
* Charged Off Loans are associated with higher revolving balance utilization (revol_util).
* Borrowers who are charged-off tend to have shorter lines of credit.
* Borrowers who are charged-off tend to have the credit pulled recently.

* Decided to addr_state as it might bias the results in favor of some states.
* Probability of charge off is almost same across all the employments lengths.
* There is no significant relationship between open_acc and Charge Off rates.
* There is no significant relationship between revol_bal and Charge Off rates.
* There is no significant relationship between total_acc and Charge Off rates.
* acc_now_delinq, delinq_amnt, tax_liens are removed since there are no significant accounts with the data.
* pub_rec_bankruptcies is correlated with  number of public records. Removed this feature since it has near zero variance.

```{r Removing the features based on the univariate analysis}

lendingClubDataFilteredWithoutCor <- lendingClubDataFilteredWithoutCor %>%
                                       select(-addr_state, -grade)

```

##### **9. Datatype Conversion **

* 1. Look for quantitative variables that are numeric and convert them into numeric.
* 2. Look for qualitative variables that are numeric and convert them into factors.
* 3. Encode the qualitative variables into dummy variables.

```{r Factor Conversion}

## Convert character, numeric and integers into factors

lendingClubDataSet <- lendingClubDataFilteredWithoutCor %>%
                        mutate(term = as.factor(term))  %>%
                        mutate(sub_grade = as.factor(sub_grade)) %>%
                        mutate(emp_length = as.factor(emp_length)) %>%
                        mutate(home_ownership = as.factor(home_ownership)) %>%
                        mutate(loan_status = as.factor(loan_status)) %>%
                        mutate(purpose = as.factor(purpose)) %>%
                        mutate(IsLoanMeetsPolicy = as.factor(IsLoanMeetsPolicy)) %>%
                        mutate(loan_amnt = as.numeric(loan_amnt)) %>%
                        mutate(delinq_2yrs = as.numeric(delinq_2yrs)) %>%
                        mutate(inq_last_6mths = as.numeric(inq_last_6mths)) %>%
                        mutate(open_acc = as.numeric(open_acc)) %>%
                        mutate(pub_rec = as.numeric(pub_rec)) %>%
                        mutate(revol_bal = as.numeric(revol_bal)) %>%
                        mutate(lastCreditPulledYear = as.factor(lastCreditPulledYear)) %>%
                        mutate(earliestCreditLineYear = as.factor(earliestCreditLineYear))

```

```{r looking at final lendingClubDataSet}
table(sapply(lendingClubDataSet[1,],class))
names(lendingClubDataSet)
dim(lendingClubDataSet)
```


##### **10. Splitting the Training & Test Datasets **

```{r Train-Test Split}

set.seed(123)

trainDataIndex <- createDataPartition(lendingClubDataSet$loan_status, p = .7, list = FALSE)

lendingClubTrain   <- lendingClubDataSet[trainDataIndex, ]
lendingClubTest    <- lendingClubDataSet[-trainDataIndex, ]

```

##### **11. Remove Skewness via. transformations **
 
```{r Look at Skew Train}

quantitativeColumns   <- names(lendingClubTrain) [sapply(lendingClubTrain[1, ], class) == "numeric"]
qualitativeColumns    <- names(lendingClubTrain) [sapply(lendingClubTrain[1, ], class) != "numeric"] 

skew <- sapply(lendingClubTrain[quantitativeColumns], e1071::skewness)
skew <- abs(skew) > 2
skewedColumns <- names(lendingClubTrain %>% select(all_of(quantitativeColumns)))[skew]
skewedColumns
```

```{r apply transformations Train}

transformedlendingClubTrain <- lendingClubTrain %>% 
                                 select(annual_inc, revol_bal) %>%
                                 preProcess(method = 'YeoJohnson') %>%
                                 predict(newdata = lendingClubTrain %>% select(annual_inc, revol_bal))

lendingClubTrain            <- cbind(
                                    lendingClubTrain %>% select(-annual_inc, -revol_bal)
                                   ,transformedlendingClubTrain
                                   )

```


```{r Look at Skew Test}

quantitativeColumnsTest   <- names(lendingClubTest) [sapply(lendingClubTest[1, ], class) == "numeric"]
qualitativeColumnsTest    <- names(lendingClubTest) [sapply(lendingClubTest[1, ], class) != "numeric"] 

skewTest <- sapply(lendingClubTest[quantitativeColumnsTest], e1071::skewness)
skewTest <- abs(skewTest) > 2
skewedColumnsTest <- names(lendingClubTest %>% select(all_of(quantitativeColumnsTest)))[skewTest]
skewedColumnsTest
```

```{r apply transformations Test}

transformedlendingClubTest <- lendingClubTest %>% 
                                 select(annual_inc, revol_bal) %>%
                                 preProcess(method = 'YeoJohnson') %>%
                                 predict(newdata = lendingClubTest %>% select(annual_inc, revol_bal))

lendingClubTest            <- cbind(
                                    lendingClubTest %>% select(-annual_inc, -revol_bal)
                                   ,transformedlendingClubTest
                                   )

```


### **12. Centering and Saling

```{r Centering and Scaling Train}

numericFeaturesTrain       <- lendingClubTrain %>% select_if(is.numeric)
nonNumericFeaturesTrain    <- lendingClubTrain %>% select_if(~!is.numeric(.x))

numericFeaturesTrainScaled <- numericFeaturesTrain %>% 
                                preProcess(.) %>%
                                predict(newdata = numericFeaturesTrain)

lendingClubTrain           <- cbind(numericFeaturesTrainScaled, nonNumericFeaturesTrain)

```

```{r Centering and Scaling Test}

numericFeaturesTest       <- lendingClubTest %>% select_if(is.numeric)
nonNumericFeaturesTest    <- lendingClubTest %>% select_if(~!is.numeric(.x))

numericFeaturesTestScaled <- numericFeaturesTest %>% 
                                preProcess(.) %>%
                                predict(newdata = numericFeaturesTest)

lendingClubTest           <- cbind(numericFeaturesTestScaled, nonNumericFeaturesTest)

```

```{r Look at the dimensions}

dim(lendingClubTrain)
dim(lendingClubTest)

```

##### **13. Supervisor proportions **

```{r Supervisor Proportions/Balance}

  lendingClubTrain %>% 
    group_by(loan_status) %>%
    summarise( Count = n() ) %>% 
    mutate(percentage = Count/sum(Count) * 100)
    
```


#### **14. re-balance the data sets **

* Using Downsampling method, we will re-balance the dataset, since there is some class imbalance: https://www.r-bloggers.com/2019/04/methods-for-dealing-with-imbalanced-data/
* Not able to use SMOTE technique in R, since SMOTE technique needs all the features to be numerical, and it does not work well with encoded categorical data.


```{r rebalance the dataset}

lendingClubTrainRebalanced <- downSample(x=lendingClubTrain[,names(lendingClubTrain) != "loan_status"], y=lendingClubTrain$loan_status, yname = "loan_status")

lendingClubTrainRebalancedX  <- lendingClubTrainRebalanced %>% select(-loan_status)
lendingClubTrainRebalancedY  <- lendingClubTrainRebalanced %>% select(loan_status)

lendingClubTrainX            <- lendingClubTrain %>% select(-loan_status)
lendingClubTrainY            <- lendingClubTrain %>% select(loan_status)

lendingClubTestX             <- lendingClubTest %>% select(-loan_status)
lendingClubTestY             <- lendingClubTest %>% select(loan_status)

```

```{r Supervisor Proportions after balancing}
  
  lendingClubTrainRebalanced %>% 
    group_by(loan_status) %>%
    summarise( Count = n() ) %>% 
    mutate(percentage = Count/sum(Count) * 100)

 lendingClubTest %>% 
    group_by(loan_status) %>%
    summarise( Count = n() ) %>% 
    mutate(percentage = Count/sum(Count) * 100)
    
```

```{r removing lastCreditPulledYear, earliestCreditLineYear since they are reducing sensitivity}

#Removed these columns after running the models.

lendingClubTrainReduced            <- lendingClubTrain            %>% select(-lastCreditPulledYear, -earliestCreditLineYear)
lendingClubTestReduced             <- lendingClubTest             %>% select(-lastCreditPulledYear, -earliestCreditLineYear)
lendingClubTrainRebalancedReduced  <- lendingClubTrainRebalanced  %>% select(-lastCreditPulledYear, -earliestCreditLineYear)

lendingClubTrainXReduced           <- lendingClubTrainX           %>% select(-lastCreditPulledYear, -earliestCreditLineYear)
lendingClubTestXReduced            <- lendingClubTestX            %>% select(-lastCreditPulledYear, -earliestCreditLineYear)
lendingClubTrainRebalancedXReduced <- lendingClubTrainRebalancedX %>% select(-lastCreditPulledYear, -earliestCreditLineYear)


```

## ** Modelling **


#### 1. Logistic regression

```{r logistic regression}
set.seed(123)

numericColumns   <- names(lendingClubTrainXReduced) [sapply(lendingClubTrainXReduced[1, ], class) == "numeric"]
factorColumns    <- names(lendingClubTrainXReduced) [sapply(lendingClubTrainXReduced[1, ], class) == "factor"]

XtrainQualitativeFeature  <- select(lendingClubTrainXReduced, all_of(factorColumns))
dummyModel                <- dummyVars(~., data = XtrainQualitativeFeature, fullRank = TRUE)
XtrainQualFeaturesEncoded <- predict(dummyModel, XtrainQualitativeFeature, drop2nd = TRUE)


XTrain        = cbind(
                       XtrainQualFeaturesEncoded
                      ,lendingClubTrainXReduced %>% select(all_of(numericColumns))
                     )

XtrainRebalancedQualitativeFeature  <- select(lendingClubTrainRebalancedXReduced, all_of(factorColumns))
dummyModel                          <- dummyVars(~., data = XtrainRebalancedQualitativeFeature, fullRank = TRUE)
XtrainRebalancedQualFeaturesEncoded <- predict(dummyModel, XtrainRebalancedQualitativeFeature, drop2nd = TRUE)


XTrainRebalanced        = cbind(
                                 XtrainRebalancedQualFeaturesEncoded
                                ,lendingClubTrainRebalancedXReduced %>% select(all_of(numericColumns))
                               )

YtrainRelevel = relevel(lendingClubTrainY$loan_status, ref = 'Charged Off')
YtestRelevel  = relevel(lendingClubTestY$loan_status,  ref = 'Charged Off')

YtrainBalancedRelevel = relevel(lendingClubTrainRebalancedY$loan_status, ref = 'Charged Off')

trControl     = trainControl(method = "cv", number = 10)

outLogistic   = train(
                        x         = XTrain
                      , y         = YtrainRelevel
                      , method    = 'glm'
                      , trControl = trControl
                     )

outLogisticBalanced   = train(
                                x         = XTrainRebalanced
                              , y         = YtrainBalancedRelevel
                              , method    = 'glm'
                              , trControl = trControl
                             )

```

```{r predictions - Original}

numericColumns   <- names(lendingClubTestXReduced) [sapply(lendingClubTestXReduced[1, ], class) == "numeric"]
factorColumns    <- names(lendingClubTestXReduced) [sapply(lendingClubTestXReduced[1, ], class) == "factor"]

XtestQualitativeFeature  <- select(lendingClubTestXReduced, all_of(factorColumns))
dummyModel               <- dummyVars(~., data = XtestQualitativeFeature, fullRank = TRUE)
XtestQualFeaturesEncoded <- predict(dummyModel, XtestQualitativeFeature, drop2nd = TRUE)

XTest        = cbind(
                       XtestQualFeaturesEncoded
                      ,lendingClubTestXReduced %>% select(all_of(numericColumns))
                     )

YhatTestProbLR = predict(outLogistic, XTest, type = 'prob')

calibProbs = calibration(YtestRelevel ~ YhatTestProbLR$'Charged Off', cuts = 5)
xyplot(calibProbs)

```

```{r confusion matrix - Original}

YhatTestLR           = predict(outLogistic, XTest, type = 'raw')

confusionMatrixOutLR = confusionMatrix(reference = YtestRelevel, data = YhatTestLR)
confusionMatrixOutLR$overall[1]
confusionMatrixOutLR$byClass[7]


print(confusionMatrixOutLR$table)

print(confusionMatrixOutLR$overall[1:2])
print(confusionMatrixOutLR$byClass[1:2])

rocCurveLR = roc(lendingClubTestY$loan_status, YhatTestProbLR$'Charged Off')

plot(rocCurveLR, legacy.axes=TRUE)
rocCurveLR$auc

```

```{r predictions - Balanced}

YhatTestProbLRBalanced = predict(outLogisticBalanced, XTest, type = 'prob')

calibProbsBalanced = calibration(YtestRelevel ~ YhatTestProbLRBalanced$'Charged Off', cuts = 5)
xyplot(calibProbsBalanced)

```

```{r confusion matrix Balanced}

YhatTestLRBalanced           = predict(outLogisticBalanced, XTest, type = 'raw')

confusionMatrixOutLRBalanced = confusionMatrix(reference = YtestRelevel, data = YhatTestLRBalanced)
confusionMatrixOutLRBalanced$overall[1]
confusionMatrixOutLRBalanced$byClass[7]

print(confusionMatrixOutLRBalanced$table)

print(confusionMatrixOutLRBalanced$overall[1:2])
print(confusionMatrixOutLRBalanced$byClass[1:2])

rocCurveLRBalanced = roc(lendingClubTestY$loan_status, YhatTestProbLRBalanced$'Charged Off')

plot(rocCurveLRBalanced, legacy.axes=TRUE)
rocCurveLRBalanced$auc

```

### 2. Logistic Elastic Net

```{r Logistic Elastic Net}

set.seed(123)

K            = 10
trainControl = trainControl(method = "cv", number = K)
tuneGrid <- expand.grid(
                         lambda = seq(1e-6, .8 , length = 30)
                        ,alpha  = c(0, 0.25, 0.5, 0.75, 1.0)
                       )

elasticOut   = train(
                       XTrainRebalanced
                     , lendingClubTrainRebalancedY$loan_status
                     , method = "glmnet"
                     , trControl = trainControl
                     , tuneLength = 10
                     #, tuneGrid = tuneGrid
                    )

elasticOut
plot(elasticOut)

alphaHat         <- elasticOut$finalModel$tuneValue$alpha
lambdaHat        <- elasticOut$finalModel$tuneValue$lambda
cbind(alphaHat, lambdaHat)

glmnetOut        <- glmnet(x = XTrainRebalanced, y = lendingClubTrainRebalancedY$loan_status, alpha = alphaHat, standardize = FALSE, family = "binomial")

```


```{r Predictions Elastic NET}

probHatTest    <- predict(glmnetOut, as.matrix(XTest), s = lambdaHat, type = "response")
YHatTestGLMNET <- ifelse(probHatTest > 0.5, "Charged Off", "Paid Fully")

```


```{r Confusion Matrix - ELASTIC NET}

confusionMatrix   <- table(YHatTestGLMNET, lendingClubTestY$loan_status)
confusionMatrix

sensitivity       <- confusionMatrix[1,1]/sum(confusionMatrix[,1])
specificity       <- confusionMatrix[2,2]/sum(confusionMatrix[,2])
precision         <- confusionMatrix[1,1]/sum(confusionMatrix[1,])

PredictionMetrics <- data.frame(sensitivity, specificity, precision)
PredictionMetrics

YHatTestGLMNETNumeric = as.numeric(probHatTest)
roc  = roc(response = lendingClubTestY$loan_status, YHatTestGLMNETNumeric)
plot(roc)
roc$auc

```


### 3.a. Decision Tree (With original Training Data)

```{r Training the Decision Tree classifier with criterion as information gain - Original Data}
set.seed(123)

trControl                 <- trainControl(method = "repeatedcv", repeats = 1, number = 10)

decicionTreeModelInf      <- train(
                                     x          = lendingClubTrainX
                                   , y          = lendingClubTrainY$loan_status
                                   , method     = "rpart"
                                   , tuneLength =  20
                                   , trControl  = trControl
                                   , parms      = list(split = "information")
                                   , metric     = 'Kappa'
                                  )

decicionTreeModelInf
```


```{r Decision Tree Confusion Matrix  - Original Data}

rpart.plot(decicionTreeModelInf$finalModel)
plot(decicionTreeModelInf$finalModel,margin= rep(.1,4))
text(decicionTreeModelInf$finalModel, cex = 0.4, digits = 1)

YHatDecisionTreeInf  <- predict(decicionTreeModelInf, lendingClubTestX)

confusionMatrixInf   <- table(YHatDecisionTreeInf, lendingClubTestY$loan_status)
confusionMatrixInf

sensitivityInf       <- confusionMatrixInf[1,1]/sum(confusionMatrixInf[,1])
specificityInf       <- confusionMatrixInf[2,2]/sum(confusionMatrixInf[,2])
precisionInf         <- confusionMatrixInf[1,1]/sum(confusionMatrixInf[1,])

PredictionMetricsInf <- data.frame(sensitivityInf, specificityInf, precisionInf)
PredictionMetricsInf

```

```{r Training the Decision Tree classifier with criterion as gini index  - Original Data}

set.seed(123)

trControl                     <- trainControl(method = "repeatedcv", repeats = 1, number = 10)

decicionTreeModelGini         <- train(
                                         x          = lendingClubTrainX
                                       , y          = lendingClubTrainY$loan_status
                                       , method     = "rpart"
                                       , tuneLength =  20
                                       , trControl  = trControl
                                       , parms      = list(split = "gini")
                                       , metric     = 'Kappa'
                                      )


decicionTreeModelGini

```


```{r  Decision Tree - Gini Index Confusion Matrix  - Original Data}

rpart.plot(decicionTreeModelGini$finalModel)
plot(decicionTreeModelGini$finalModel,margin= rep(.1,4))
text(decicionTreeModelGini$finalModel, cex = 0.4, digits = 1)

YHatDecisionTreeGini  <- predict(decicionTreeModelGini, lendingClubTestX)

confusionMatrixGini   <- table(YHatDecisionTreeGini, lendingClubTestY$loan_status)
confusionMatrixGini

sensitivityGini       <- confusionMatrixGini[1,1]/sum(confusionMatrixGini[,1])
specificityGini       <- confusionMatrixGini[2,2]/sum(confusionMatrixGini[,2])
precisionGini         <- confusionMatrixGini[1,1]/sum(confusionMatrixGini[1,])

PredictionMetricsGini <- data.frame(sensitivityGini, specificityGini, precisionGini)
PredictionMetricsGini

```

### 3.b. Decision Tree (With Rebalanced Training Data)

```{r Training the Decision Tree classifier with criterion as information gain - Balanced Data}
set.seed(123)

trControl                 <- trainControl(method = "repeatedcv", repeats = 2, number = 10)

decicionTreeModelInf      <- train(
                                     x          = lendingClubTrainRebalancedXReduced
                                   , y          = lendingClubTrainRebalancedY$loan_status
                                   , method     = "rpart"
                                   , tuneLength =  20
                                   , trControl  = trControl
                                   , parms      = list(split = "information")
                                  )

decicionTreeModelInf
```


```{r Decision Tree Confusion Matrix  - Balanced Data}

rpart.plot(decicionTreeModelInf$finalModel)
plot(decicionTreeModelInf$finalModel,margin= rep(.1,4))
text(decicionTreeModelInf$finalModel, cex = 0.4, digits = 1)

YHatDecisionTreeInf  <- predict(decicionTreeModelInf, lendingClubTestXReduced)

confusionMatrixInf   <- table(YHatDecisionTreeInf, lendingClubTestY$loan_status)
confusionMatrixInf

sensitivityInf       <- confusionMatrixInf[1,1]/sum(confusionMatrixInf[,1])
specificityInf       <- confusionMatrixInf[2,2]/sum(confusionMatrixInf[,2])
precisionInf         <- confusionMatrixInf[1,1]/sum(confusionMatrixInf[1,])

PredictionMetricsInf <- data.frame(sensitivityInf, specificityInf, precisionInf)
PredictionMetricsInf

```

```{r Training the Decision Tree classifier with criterion as gini index  - Balanced Data}

set.seed(123)

trControl                     <- trainControl(method = "repeatedcv", repeats = 2, number = 10)

decicionTreeModelGini         <- train(
                                         x          = lendingClubTrainRebalancedXReduced
                                       , y          = lendingClubTrainRebalancedY$loan_status
                                       , method     = "rpart"
                                       , tuneLength =  20
                                       , trControl  = trControl
                                       , parms      = list(split = "gini")
                                      )


decicionTreeModelGini

```

```{r Decision Tree Confusion Matrix Gini Index}

rpart.plot(decicionTreeModelGini$finalModel)
plot(decicionTreeModelGini$finalModel,margin= rep(.1,4))
text(decicionTreeModelGini$finalModel, cex = 0.4, digits = 1)

YHatDecisionTreeGini  <- predict(decicionTreeModelGini, lendingClubTestXReduced)

confusionMatrixGini   <- table(YHatDecisionTreeGini, lendingClubTestY$loan_status)
confusionMatrixGini

sensitivityGini       <- confusionMatrixGini[1,1]/sum(confusionMatrixGini[,1])
specificityGini       <- confusionMatrixGini[2,2]/sum(confusionMatrixGini[,2])
precisionGini         <- confusionMatrixGini[1,1]/sum(confusionMatrixGini[1,])

PredictionMetricsGini <- data.frame(sensitivityGini, specificityGini, precisionGini)
PredictionMetricsGini

```

### 4. Random Forest Model

```{r Random Forest}

set.seed(123)

tuneGridRanger      <- data.frame(
                                   splitrule = "gini"
                                 , min.node.size = 5
                                 , mtry = round(sqrt(ncol(lendingClubTrainRebalancedX)))
                                 )

tuneGridRanger      <- expand.grid(
                                   splitrule     = c("gini", "extratrees")
                                 , min.node.size = c(1, 3, 5, 7)
                                 , mtry          = c(2, 3, 4, 5)
                                 )

trControl           <- trainControl(method = "repeatedcv", repeats = 1, number = 10)

randomForestModel   <- train(
                              x         = lendingClubTrainRebalancedXReduced
                            , y         = lendingClubTrainRebalancedY$loan_status
                            , method    = "ranger"
                            , tuneGrid  = tuneGridRanger
                            , trControl = trControl
                           )

randomForestModel


```

```{r Random Forest - Ranger - Confusion Matrix}

YHatRandomForest  <- predict(randomForestModel, lendingClubTestXReduced)

confusionMatrixRandomForest   <- table(YHatRandomForest, lendingClubTestY$loan_status)
confusionMatrixRandomForest

sensitivityRandomForest       <- confusionMatrixRandomForest[1,1]/sum(confusionMatrixRandomForest[,1])
specificityRandomForest       <- confusionMatrixRandomForest[2,2]/sum(confusionMatrixRandomForest[,2])
precisionRandomForest         <- confusionMatrixRandomForest[1,1]/sum(confusionMatrixRandomForest[1,])

PredictionMetricsRandomForest <- data.frame(sensitivityRandomForest, specificityRandomForest, precisionRandomForest)
PredictionMetricsRandomForest

```

```{r Random Forest - 2}

set.seed(123)

trControl           <- trainControl(method = "repeatedcv", repeats = 1, number = 10)

randomForestModel_2   <- train(
                                x          = lendingClubTrainRebalancedXReduced
                              , y          = lendingClubTrainRebalancedY$loan_status
                              , method     = "rf"
                              , tuneLength = 10
                              , ntree      = 100
                              , importance = TRUE
                              #, metric     = 'Kappa'
                              , trControl = trControl
                              )

randomForestModel_2

```

```{r Random Forest -  Confusion Matrix}

YHatRandomForest_2  <- predict(randomForestModel_2, lendingClubTestXReduced)

confusionMatrixRandomForest_2   <- table(YHatRandomForest_2, lendingClubTestY$loan_status)
confusionMatrixRandomForest_2

sensitivityRandomForest_2       <- confusionMatrixRandomForest_2[1,1]/sum(confusionMatrixRandomForest_2[,1])
specificityRandomForest_2       <- confusionMatrixRandomForest_2[2,2]/sum(confusionMatrixRandomForest_2[,2])
precisionRandomForest_2         <- confusionMatrixRandomForest_2[1,1]/sum(confusionMatrixRandomForest_2[1,])

PredictionMetricsRandomForest_2 <- data.frame(sensitivityRandomForest_2, specificityRandomForest_2, precisionRandomForest_2)
PredictionMetricsRandomForest_2

```


### 5. Boosting Model


```{r Converting the data}
XTrain = sparse.model.matrix(loan_status ~., data = lendingClubTrainRebalancedReduced)
XTest  = sparse.model.matrix(loan_status ~., data = lendingClubTestReduced)
```

```{r Boosting Model with logloss}

set.seed(123)

trainControl = trainControl(method = "repeatedcv", repeats = 1, number = 10, verboseIter = FALSE)

B = seq(100,500,length.out = 10)

tuneGrid = data.frame(
                        'nrounds'          = B 
                      , 'max_depth'        = 6
                      , 'eta'              = .01
                      , 'gamma'            = 0
                      , 'colsample_bytree' = 1
                      , 'min_child_weight' = 0
                      , 'subsample'        = 0.5
                      #, 'objective'        = "binary:logistic" #reg:logistic
                      #, 'eval_metric'      = "logloss" #error, error@t, auc
                     )

xgBoostModel <- train(
                        x           = XTrain
                      , y           = lendingClubTrainRebalancedY$loan_status
                      , method      = "xgbTree"
                      , tuneGrid    = tuneGrid
                      , trControl   = trainControl
                      , objective   = "binary:logistic"
                      , eval_metric = "logloss"
                      #, metric = 'Accuracy'
                     )

YhatXGBoost  <- predict(xgBoostModel, XTest)

```

```{r Confusion Matrix - XG Boost with logloss}

confusionMatrixXGBoost   <- table(YhatXGBoost, lendingClubTestY$loan_status)
confusionMatrixXGBoost

sensitivityXGBoost       <- confusionMatrixXGBoost[1,1]/sum(confusionMatrixXGBoost[,1])
specificityXGBoost       <- confusionMatrixXGBoost[2,2]/sum(confusionMatrixXGBoost[,2])
precisionXGBoost         <- confusionMatrixXGBoost[1,1]/sum(confusionMatrixXGBoost[1,])

PredictionMetricsXGBoost <- data.frame(sensitivityXGBoost, specificityXGBoost, precisionXGBoost)
PredictionMetricsXGBoost

YhatXGBoost = as.numeric(YhatXGBoost)
rocXGBoost = roc(response = lendingClubTestY$loan_status, YhatXGBoost)
plot(rocXGBoost)
rocXGBoost$auc

```


```{r Boosting Model with error}
set.seed(123)

trainControl = trainControl(method = "repeatedcv", repeats = 1, number = 10, verboseIter = FALSE)

B = seq(100,500,length.out = 10)

tuneGrid = data.frame(
                        'nrounds'          = B 
                      , 'max_depth'        = 6
                      , 'eta'              = .01
                      , 'gamma'            = 0
                      , 'colsample_bytree' = 1
                      , 'min_child_weight' = 0
                      , 'subsample'        = 0.5
                      #, 'objective'        = "binary:logistic" #reg:logistic
                      #, 'eval_metric'      = "error" #logloss, error, error@t, auc
                     )

xgBoostModel2 <- train(
                         x           = XTrain
                       , y           = lendingClubTrainRebalancedY$loan_status
                       , method      = "xgbTree"
                       , tuneGrid    = tuneGrid
                       , trControl   = trainControl
                       , objective   = "binary:logistic"
                       , eval_metric = "error"
                       #, metric = 'Accuracy'
                     )

YhatXGBoost2  <- predict(xgBoostModel2, XTest)

```

```{r Confusion Matrix - XG Boost with Error}

confusionMatrixXGBoost2   <- table(YhatXGBoost2, lendingClubTestY$loan_status)
confusionMatrixXGBoost2

sensitivityXGBoost2       <- confusionMatrixXGBoost2[1,1]/sum(confusionMatrixXGBoost2[,1])
specificityXGBoost2       <- confusionMatrixXGBoost2[2,2]/sum(confusionMatrixXGBoost2[,2])
precisionXGBoost2         <- confusionMatrixXGBoost2[1,1]/sum(confusionMatrixXGBoost2[1,])

PredictionMetricsXGBoost2 <- data.frame(sensitivityXGBoost2, specificityXGBoost2, precisionXGBoost2)
PredictionMetricsXGBoost2

YhatXGBoost2 = as.numeric(YhatXGBoost2)
rocXGBoost2 = roc(response = lendingClubTestY$loan_status, YhatXGBoost2)
plot(rocXGBoost2)
rocXGBoost2$auc

```

```{r Boosting Model without params}
set.seed(123)

trainControl = trainControl(method = "repeatedcv", repeats = 1, number = 10, verboseIter = FALSE)

B = seq(100,500,length.out = 10)

tuneGrid = data.frame(
                        'nrounds'          = B 
                      , 'max_depth'        = 6
                      , 'eta'              = .01
                      , 'gamma'            = 0
                      , 'colsample_bytree' = 1
                      , 'min_child_weight' = 0
                      , 'subsample'        = 0.5
                      #, 'objective'        = "binary:logistic" #reg:logistic
                      #, 'eval_metric'      = "error" #logloss, error, error@t, auc
                     )

xgBoostModel3 <- train(
                         x           = XTrain
                       , y           = lendingClubTrainRebalancedY$loan_status
                       , method      = "xgbTree"
                       , tuneGrid    = tuneGrid
                       , trControl   = trainControl
                       #, metric = 'Accuracy'
                     )

YhatXGBoost3  <- predict(xgBoostModel3, XTest)

```

```{r Confusion Matrix - XG Boost without Parameters}

confusionMatrixXGBoost3   <- table(YhatXGBoost3, lendingClubTestY$loan_status)
confusionMatrixXGBoost3

sensitivityXGBoost3       <- confusionMatrixXGBoost3[1,1]/sum(confusionMatrixXGBoost3[,1])
specificityXGBoost3       <- confusionMatrixXGBoost3[2,2]/sum(confusionMatrixXGBoost3[,2])
precisionXGBoost3         <- confusionMatrixXGBoost3[1,1]/sum(confusionMatrixXGBoost3[1,])

PredictionMetricsXGBoost3 <- data.frame(sensitivityXGBoost3, specificityXGBoost3, precisionXGBoost3)
PredictionMetricsXGBoost3

YhatXGBoost3 = as.numeric(YhatXGBoost3)
rocXGBoost3 = roc(response = lendingClubTestY$loan_status, YhatXGBoost3)
plot(rocXGBoost3)
rocXGBoost3$auc

```

### Variable Importance

```{r}
library(vip)
output.forest <- ranger(loan_status~., data = lendingClubTrainRebalancedReduced, importance = 'impurity')
vi_tree <- vip(output.forest)
vi_tree
```

```{r}
library(vip)
output.forest <- ranger(loan_status~., data = lendingClubTrainRebalancedReduced, importance = 'permutation')
vi_tree <- vip(output.forest)
vi_tree
```

```{r Boosting Importance}

boostImportance0 = xgb.importance(model = xgBoostModel$finalModel)
boostImportance0
caret::varImp(xgBoostModel)

```

```{r Random Forest Importance}
varImpPlot(randomForestModel_2$finalModel)
caret::varImp(randomForestModel_2$finalModel)
```



```{r Confusion Matrix Decision Tree - Reduced Threshold}

YHatDecisionTreeInfProb           <- predict(decicionTreeModelInf, lendingClubTestXReduced, type = "prob")

YhatDecisionTreeNewT              <- ifelse(YHatDecisionTreeInfProb$`Charged Off` > .3, 'Charged Off', 'Fully Paid') %>% as.factor

confusionMatrixDecisionTreeNewT   <- table(YhatDecisionTreeNewT, lendingClubTestY$loan_status)
confusionMatrixDecisionTreeNewT

sensitivityDecisionTreeNewT       <- confusionMatrixDecisionTreeNewT[1,1]/sum(confusionMatrixDecisionTreeNewT[,1])
specificityDecisionTreeNewT       <- confusionMatrixDecisionTreeNewT[2,2]/sum(confusionMatrixDecisionTreeNewT[,2])
precisionDecisionTreeNewT         <- confusionMatrixDecisionTreeNewT[1,1]/sum(confusionMatrixDecisionTreeNewT[1,])

PredictionMetricsDecisionTreeNewT <- data.frame(sensitivityDecisionTreeNewT, specificityDecisionTreeNewT, precisionDecisionTreeNewT)
PredictionMetricsDecisionTreeNewT

YhatDecisionNewTNumeric = as.numeric(YhatDecisionTreeNewT)
rocDecisionTreeNewT = roc(response = lendingClubTestY$loan_status, YhatDecisionNewTNumeric)
plot(rocDecisionTreeNewT)
rocDecisionTreeNewT$auc

confusionMatrix(data = YhatDecisionTreeNewT, ref = lendingClubTestY$loan_status)

```

```{r Confusion Matrix XGBoost - Reduced Threshold}

YhatXGBoostProb  <- predict(xgBoostModel, XTest, type = "prob")


#nrow(YhatXGBoostProb[which(YhatXGBoostProb$`Charged Off` > 0.5),])
#nrow(YhatXGBoostProb[which(YhatXGBoostProb$`Charged Off` > 0.45),])
#nrow(YhatXGBoostProb[which(YhatXGBoostProb$`Charged Off` > 0.4),])

YhatXGBoostNewT              <- ifelse(YhatXGBoostProb$`Charged Off` > .4, 'Charged Off', 'Fully Paid') %>% as.factor


confusionMatrixXGBoostNewT   <- table(YhatXGBoostNewT, lendingClubTestY$loan_status)
confusionMatrixXGBoostNewT

sensitivityXGBoostNewT       <- confusionMatrixXGBoostNewT[1,1]/sum(confusionMatrixXGBoostNewT[,1])
specificityXGBoostNewT       <- confusionMatrixXGBoostNewT[2,2]/sum(confusionMatrixXGBoostNewT[,2])
precisionXGBoostNewT         <- confusionMatrixXGBoostNewT[1,1]/sum(confusionMatrixXGBoostNewT[1,])

PredictionMetricsXGBoostNewT <- data.frame(sensitivityXGBoostNewT, specificityXGBoostNewT, precisionXGBoostNewT)
PredictionMetricsXGBoostNewT

YhatXGBoostNewTNumeric = as.numeric(YhatXGBoostNewT)
rocXGBoostNewT = roc(response = lendingClubTestY$loan_status, YhatXGBoostNewTNumeric)
plot(rocXGBoostNewT)
rocXGBoostNewT$auc

confusionMatrix(data = YhatXGBoostNewT, ref = lendingClubTestY$loan_status)

```